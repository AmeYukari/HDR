# 2024

## SAFNet——SAFNet: Selective Alignment Fusion Network for Efficient HDR Imaging（ECCV 2024）

代码未开源

面对截断的纹理和复杂的运动时，多重曝光高动态范围 (HDR) 成像是一项具有挑战性的任务。现有的基于深度学习的方法通过遵循对齐和融合管道或利用注意力机制取得了巨大的成功。然而，巨大的计算成本和推理延迟阻碍了它们部署在资源有限的设备上。在本文中，为了获得更好的效率，提出了一种用于 HDR 成像的新型选择性对齐融合网络（SAFNet）。提取金字塔特征后，它与共享解码器共同细化选定区域中有价值的区域掩模和交叉曝光运动，然后以显式方式融合高质量的 HDR 图像。这种方法可以让模型专注于寻找有价值的区域，同时估计它们易于检测且有意义的运动。为了进一步增强细节，引入了轻量级细化模块，该模块享有先前光流、选择掩模和初始预测的特权。此外，为了便于对运动较大的样本进行学习，在训练过程中提出了一种新的窗口分割裁剪方法。对公共和新开发的具有挑战性的数据集的实验表明，所提出的 SAFNet 不仅在数量和质量上超过了以前的 SOTA 竞争对手，而且运行速度更快了一个数量级。



提出数据集：**Challenge123**。相比于已有数据集有更大的运动和饱和区域



# 2023

## HyHDRNet——A Unified HDR Imaging Method with Pixel and Patch Level（CVPR 2023）

**研究机构**：西北工业大学 + 西电

**研究内容**：在动态场景中将具有不同曝光度的低动态范围 (LDR) 图像映射到高动态范围 (HDR)，解决**运动和饱和同时存在**的区域的 HDR 重建难点

<img src="C:\Users\AmeYukari\AppData\Roaming\Typora\typora-user-images\image-20240819220844226.png" alt="image-20240819220844226" style="zoom:50%;" />

**研究背景**：随着深度神经网络（DNN）的成功，已有研究提出了几种基于 DNN 的方法来减轻重影，但当发生运动和饱和时，它们无法产生令人满意的结果。为了在各种情况下生成视觉上令人愉悦的 HDR 图像，我们提出了一种混合 HDR deghosting 网络（称为 HyHDRNet），以学习参考图像和非参考图像之间的复杂关系。

- HDR 成像的一种常见方式是融合一系列不同曝光的低动态范围 (LDR) 图像。 当场景和相机都是静态时，它可以恢复高质量的 HDR 图像，但是，它在动态物体或手持相机场景上会出现重影伪影。
- 基于对齐的方法采用全局（例如，单应性）或非刚性对齐（例如，光流）来校正运动区域的内容，但它们容易出错，并且由于饱和和遮挡而导致重影。
- 基于拒绝的方法尝试从曝光图像中去除运动成分，并用参考图像的内容替换它们。尽管这些方法在静态场景中获得了良好的质量，但它们丢弃了未对齐的区域，这导致移动区域的内容不足。
- 基于补丁的方法利用补丁级对齐来传输和融合相似的内容。虽然这些基于补丁的方法实现了更好的性能，但它们的计算成本很高。

**方法框架图**：

HyHDRNet 由两个子网络组成，包括一个内容对齐子网络和一个基于Transformer的融合子网络。

<img src="E:\项目\华为HDR\paperpics\HyHDRNet_structure.png" alt="HyHDRNet_structure" style="zoom:50%;" />

**输入**：动态场景中具有不同曝光的 LDR 图像 $\{L_1,L_2,L_3\}$，其中 $L_2$ 为参考图像

**输出**：无重影伪影的 HDR 图像



## SCTNet——Alignment-free HDR Deghosting with Semantics Consistent Transformer（ICCV 2023）

**开源 Code & Dataset**：https://steven-tel.github.io/sctnet/

**研究背景**：现有方法通常关注由前景和相机运动引起的输入帧之间的空间错位。 然而，目前还没有关于同时利用动态和静态上下文的研究。

<img src="E:\项目\华为HDR\paperpics\SCTNet_Motivation.png" alt="SCTNet_Motivation" style="zoom:40%;" />

**研究内容**：同时利用动态和静态上下文信息，模型同时具有空间和通道注意模块。空间注意力旨在处理图像内相关性以对动态运动进行建模，而通道注意力使图像间交织以增强跨帧的语义一致性。

<img src="E:\项目\华为HDR\paperpics\SCTNet_Architecture.png" alt="SCTNet_Architecture" style="zoom:40%;" />



## RawHDR——RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image（ICCV 2023）

注意到 RAW 图像位深更大，且相机 CRF 在绿色通道的响应曲线优于红色和蓝色通道，所以选用 RAW 图像作为输入并围绕绿色通道进行构建方法。

<img src="E:\项目\华为HDR\paperpics\RawHDR_Architecture.png" alt="RawHDR_Architecture" style="zoom:40%;" />



# 2022

## HDR-Transformer（CA-ViT）——Ghost-free High Dynamic Range Imaging with Context-aware Transformer（ECCV 2022）

**开源 Code**：https://github.com/megvii-research/HDR-Transformer

**研究背景**：受感受野局部性的限制，现有的基于 CNN 的方法通常在大运动和严重饱和的情况下容易产生重影伪影和强度失真。

**研究内容**：利用Transformer提取长距离依赖，解决CNN固有的局部性问题

**CA-ViT 结构**：Swin-Transformer + squeeze-and-excitation block -> Context-Aware Vision Transformer

<img src="E:\项目\华为HDR\paperpics\CA-ViT structure.png" alt="CA-ViT structure" style="zoom:50%;" />

**HDR-Transformer 结构**：

<img src="E:\项目\华为HDR\paperpics\HDR-Transformer architecture.png" alt="HDR-Transformer architecture" style="zoom:50%;" />

**Feature Attention**：简单的 卷积 -> LeakyReLU -> 卷积 -> Sigmoid 结构。



## CEN-HDR——CEN-HDR: Computationally Efficient neural Network for real-time High Dynamic Range imaging（ECCV 2022）

**开源 Code**：https://github.com/steven-tel/CEN-HDR

**研究背景**：最近的研究提出了提供高质量采集的解决方案，但代价是大量操作和缓慢的推理时间，阻碍了这些解决方案在轻量级实时系统上的实现。

**研究成果**：为实时 HDR 成像提供了一种基于光注意机制和子像素卷积运算的新颖架构，同时通过使用知识蒸馏应用网络压缩来提供有效的训练方案。

**研究内容**：发一种 HDR 成像的新方法，并同时考虑到推理时间和计算成本的限制。



<img src="E:\项目\华为HDR\paperpics\CENHDR_Architecture.png" alt="CENHDR_Architecture" style="zoom:40%;" />

注意力模块结构沿用 Bottleneck Attention Module：

<img src="E:\项目\华为HDR\paperpics\CENHDR_attention.png" alt="CENHDR_attention" style="zoom:50%;" />



# 2021

## ADNet：ADNet: Attention-guided Deformable Convolutional Network for High Dynamic Range Imaging（CVPRW 2021）

在 AHDRNet 的基础上引入了 Deformable Conv 将非参考图像与参考图像进行对齐，同时采用 AHDRNet 中相同结构的 Attention 模块得到注意力特征（$f_1^t=\mathcal{A}(f_1,f_2)*f_1$，$f_2^t=f_2$，$f_3^t=\mathcal{A}(f_2,f_3)*f_3$）。

<img src="E:\项目\华为HDR\paperpics\ADNet_architecture.png" alt="ADNet_architecture" style="zoom:50%;" />



## HDRUNet——HDRUNet: Single Image HDR Reconstruction with Denoising and Dequantization（CVPRW 2021）

**开源 Code**：https://github.com/chxy95/HDRUNet

**研究背景**：由于传感器的限制，大多数消费级数码相机只能捕捉现实场景中有限范围的亮度。 此外，成像过程中经常引入噪声和量化误差。 为了获得具有出色视觉质量的高动态范围（HDR）图像，最常见的解决方案是将具有不同曝光的多幅图像组合在一起。 然而，**获得同一场景的多个图像并不总是可行**，并且大多数 HDR 重建方法都忽略了噪声和量化损失。

**研究内容**：与均匀分布在整个图像中的高斯白噪声不同，LDR 和 HDR 图像中的噪声分布并不均匀。差异不仅存在于高光区域和非高光区域之间，而且还存在于曝光良好区域的不同位置处。这启发我们为网络设计一个**空间变量调制模块**。

网络结构：

<img src="E:\项目\华为HDR\paperpics\HDRUNet_Architecture.png" alt="HDRUNet_Architecture" style="zoom:50%;" />



# Before 2021

## NHDRRnet——Deep HDR Imaging via A Non-Local Network（TIP 2020）

通过利用深层特征空间中输入的多个 LDR 图像内的非局部相关性来消除重影伪影。采用了两分支策略。一个分支是去除重影伪像和未对齐的区域，另一个分支尝试从 LDR 图像中收集局部细节。

<img src="E:\项目\华为HDR\paperpics\NHDRRNet_Architecture.png" alt="NHDRRNet_Architecture" style="zoom:40%;" />

Triple-pass residual module 结构：

<img src="E:\项目\华为HDR\paperpics\NHDRRNet_triple_pass_residual_module.png" alt="NHDRRNet_triple_pass_residual_module" style="zoom:50%;" />



## AHDRNet——Attention-Guided Network for Ghost-Free High Dynamic Range Imaging（CVPR 2019）

首次引入了注意力机制，用于在合并特征之前识别出非参考图像中未对齐的分量，以减轻合成结果中的重影伪影

<img src="E:\项目\华为HDR\paperpics\AHDRNet_architecture.png" alt="AHDRNet_architecture" style="zoom:50%;" />

Attention模块：Concatenate—Conv—ReLU—Conv—Sigmoid

<img src="E:\项目\华为HDR\paperpics\AHDRNet_attention.png" alt="AHDRNet_attention" style="zoom:50%;" />

DRDB：稠密连接 + 残差 + dilated Conv（dilate = 2）

<img src="E:\项目\华为HDR\paperpics\AHDRNet_DRDB.png" alt="AHDRNet_DRDB" style="zoom:50%;" />



## HDRCNN——HDR image reconstruction from a single exposure using deep CNNs（TOG 2017）

首次引入 CNN 进行 HDR 计算





## Deep High Dynamic Range Imaging of Dynamic Scenes（TOG 2017）

通过提出配对的 LDR-HDR 数据集并开发卷积神经网络（CNN）以在流对齐后融合 LDR 输入，开创了基于学习的多帧 HDR 重建。